"""
åŠè‡ªä¸»æ•°æ®åˆ†æAgent - äº¤äº’å¼ç‰ˆæœ¬
Agentæä¾›å»ºè®®ï¼Œç”¨æˆ·åšå†³ç­–
"""
import pandas as pd
import os
from typing import Dict, Any, Optional, List
from datetime import datetime

from .core.llm_client import AliyunLLMClient
from .core.report_generator import HTMLReportGenerator


class InteractiveDataAgent:
    """
    åŠè‡ªä¸»æ•°æ®åˆ†æAgent
    
    ç‰¹ç‚¹ï¼š
    1. Agentåˆ†ææ•°æ®å¹¶æä¾›å»ºè®®
    2. ç”¨æˆ·é€‰æ‹©è¦æ‰§è¡Œçš„åˆ†æ
    3. Agentæ‰§è¡Œé€‰å®šçš„åˆ†æ
    4. æ”¯æŒå¤šè½®å¯¹è¯
    """
    
    def __init__(self, api_key: str = None):
        """åˆå§‹åŒ–Agent"""
        self.llm = AliyunLLMClient(api_key)
        self.report_generator = HTMLReportGenerator()
        
        # å½“å‰çŠ¶æ€
        self.current_data = None
        self.current_file_info = {}
        self.analysis_results = {}
        self.conversation_history = []
        
        # å¯é€‰åˆ†æç±»å‹
        self.available_analyses = {
            '1': {'name': 'åŸºç¡€ç»Ÿè®¡åˆ†æ', 'desc': 'æ•°æ®æ¦‚è§ˆã€å‡å€¼ã€æ ‡å‡†å·®ç­‰åŸºç¡€ç»Ÿè®¡'},
            '2': {'name': 'ç¼ºå¤±å€¼åˆ†æ', 'desc': 'æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å’Œç¼ºå¤±å€¼åˆ†å¸ƒ'},
            '3': {'name': 'æ•°æ®åˆ†å¸ƒåˆ†æ', 'desc': 'æŸ¥çœ‹å„å˜é‡çš„åˆ†å¸ƒæƒ…å†µ'},
            '4': {'name': 'ç›¸å…³æ€§åˆ†æ', 'desc': 'åˆ†æå˜é‡ä¹‹é—´çš„ç›¸å…³å…³ç³»'},
            '5': {'name': 'å¼‚å¸¸å€¼æ£€æµ‹', 'desc': 'è¯†åˆ«æ•°æ®ä¸­çš„å¼‚å¸¸å€¼'},
            '6': {'name': 'ç®€å•è¶‹åŠ¿åˆ†æ', 'desc': 'æ—¶é—´åºåˆ—æ•°æ®çš„è¶‹åŠ¿åˆ†æ'},
            '7': {'name': 'åˆ†ç±»å˜é‡åˆ†æ', 'desc': 'åˆ†ç±»å˜é‡çš„é¢‘æ¬¡å’Œåˆ†å¸ƒ'},
            'all': {'name': 'å®Œæ•´åˆ†æ', 'desc': 'æ‰§è¡Œæ‰€æœ‰é€‚ç”¨çš„åˆ†æ'}
        }
    
    def start_analysis(self, file_path: str) -> None:
        """å¼€å§‹äº¤äº’å¼åˆ†ææµç¨‹"""
        print("ğŸ¤– ä½ å¥½ï¼æˆ‘æ˜¯æ•°æ®åˆ†æAgentï¼Œæˆ‘å°†å¸®åŠ©ä½ åˆ†ææ•°æ®ã€‚")
        print("=" * 60)
        
        # æ­¥éª¤1: åŠ è½½æ•°æ®
        if not self._load_data(file_path):
            return
        
        # æ­¥éª¤2: æ•°æ®åˆæ­¥æ£€æŸ¥å’Œå»ºè®®
        suggestions = self._analyze_and_suggest()
        
        # æ­¥éª¤3: ç”¨æˆ·é€‰æ‹©åˆ†æ
        selected_analyses = self._user_select_analyses(suggestions)
        
        # æ­¥éª¤4: æ‰§è¡Œåˆ†æ
        self._execute_analyses(selected_analyses)
        
        # æ­¥éª¤5: ç”ŸæˆæŠ¥å‘Š
        self._generate_final_report()
        
        # æ­¥éª¤6: ç»§ç»­å¯¹è¯
        self._continue_conversation()
    
    def _load_data(self, file_path: str) -> bool:
        """åŠ è½½å¹¶æ£€æŸ¥æ•°æ®"""
        print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ–‡ä»¶: {os.path.basename(file_path)}")
        
        try:
            file_ext = os.path.splitext(file_path)[1].lower()
            
            if file_ext == '.csv':
                encodings = ['utf-8', 'gbk', 'gb2312']
                for encoding in encodings:
                    try:
                        self.current_data = pd.read_csv(file_path, encoding=encoding)
                        print(f"âœ… ä½¿ç”¨{encoding}ç¼–ç æˆåŠŸè¯»å–CSVæ–‡ä»¶")
                        break
                    except UnicodeDecodeError:
                        continue
                if self.current_data is None:
                    print("âŒ æ— æ³•è¯»å–CSVæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ç¼–ç ")
                    return False
                    
            elif file_ext in ['.xlsx', '.xls']:
                self.current_data = pd.read_excel(file_path)
                print("âœ… æˆåŠŸè¯»å–Excelæ–‡ä»¶")
            else:
                print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
                print("æ”¯æŒçš„æ ¼å¼: .csv, .xlsx, .xls")
                return False
            
            # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
            self.current_file_info = {
                'file_name': os.path.basename(file_path),
                'shape': self.current_data.shape,
                'columns': self.current_data.columns.tolist(),
                'dtypes': {col: str(dtype) for col, dtype in self.current_data.dtypes.items()}
            }
            
            # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            print(f"ğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯:")
            print(f"   â€¢ è¡Œæ•°: {self.current_data.shape[0]}")
            print(f"   â€¢ åˆ—æ•°: {self.current_data.shape[1]}")
            print(f"   â€¢ åˆ—å: {', '.join(self.current_data.columns[:5])}")
            if len(self.current_data.columns) > 5:
                print(f"         (è¿˜æœ‰{len(self.current_data.columns)-5}åˆ—...)")
            print()
            
            return True
            
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False
    
    def _analyze_and_suggest(self) -> List[str]:
        """åˆ†ææ•°æ®ç‰¹å¾å¹¶æä¾›å»ºè®®"""
        print("ğŸ§  æ­£åœ¨åˆ†ææ•°æ®ç‰¹å¾...")
        
        df = self.current_data
        suggestions = []
        
        # åˆ†ææ•°æ®ç±»å‹
        numeric_cols = df.select_dtypes(include=['number']).columns
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns
        datetime_cols = []
        
        # æ£€æŸ¥å¯èƒ½çš„æ—¶é—´åˆ—
        for col in df.columns:
            if any(keyword in col.lower() for keyword in ['date', 'time', 'æ—¶é—´', 'æ—¥æœŸ']):
                try:
                    pd.to_datetime(df[col])
                    datetime_cols.append(col)
                except:
                    pass
        
        # åŸºäºæ•°æ®ç‰¹å¾ç»™å‡ºå»ºè®®
        print("ğŸ’¡ åŸºäºä½ çš„æ•°æ®ç‰¹å¾ï¼Œæˆ‘å»ºè®®è¿›è¡Œä»¥ä¸‹åˆ†æ:")
        print()
        
        # å¿…è¦çš„åŸºç¡€åˆ†æ
        suggestions.append('1')  # åŸºç¡€ç»Ÿè®¡
        print("ğŸ”¹ åŸºç¡€ç»Ÿè®¡åˆ†æ - å¿…é¡»è¿›è¡Œï¼Œäº†è§£æ•°æ®åŸºæœ¬ç‰¹å¾")
        
        # ç¼ºå¤±å€¼æ£€æŸ¥
        if df.isnull().sum().sum() > 0:
            suggestions.append('2')
            print("ğŸ”¸ ç¼ºå¤±å€¼åˆ†æ - å‘ç°ç¼ºå¤±æ•°æ®ï¼Œå»ºè®®æ£€æŸ¥")
        
        # æ•°å€¼å‹å˜é‡åˆ†æ
        if len(numeric_cols) > 0:
            suggestions.append('3')
            print(f"ğŸ”¹ æ•°æ®åˆ†å¸ƒåˆ†æ - å‘ç°{len(numeric_cols)}ä¸ªæ•°å€¼å‹å˜é‡")
            
            if len(numeric_cols) >= 2:
                suggestions.append('4')
                print("ğŸ”¹ ç›¸å…³æ€§åˆ†æ - å¤šä¸ªæ•°å€¼å˜é‡ï¼Œå¯åˆ†æç›¸å…³æ€§")
        
        # åˆ†ç±»å˜é‡åˆ†æ
        if len(categorical_cols) > 0:
            suggestions.append('7')
            print(f"ğŸ”¹ åˆ†ç±»å˜é‡åˆ†æ - å‘ç°{len(categorical_cols)}ä¸ªåˆ†ç±»å˜é‡")
        
        # æ—¶é—´åºåˆ—åˆ†æ
        if len(datetime_cols) > 0:
            suggestions.append('6')
            print(f"ğŸ”¹ è¶‹åŠ¿åˆ†æ - å‘ç°æ—¶é—´åˆ—: {', '.join(datetime_cols)}")
        
        print()
        return suggestions
    
    def _user_select_analyses(self, suggestions: List[str]) -> List[str]:
        """ç”¨æˆ·é€‰æ‹©è¦æ‰§è¡Œçš„åˆ†æ"""
        print("è¯·é€‰æ‹©è¦æ‰§è¡Œçš„åˆ†æ (å¯å¤šé€‰ï¼Œç”¨ç©ºæ ¼åˆ†éš”):")
        print()
        
        # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨åˆ†æ
        for key, info in self.available_analyses.items():
            if key == 'all':
                continue
            status = "âœ… æ¨è" if key in suggestions else "âšª å¯é€‰"
            print(f"{key}. {info['name']} - {info['desc']} {status}")
        
        print("all. å®Œæ•´åˆ†æ - æ‰§è¡Œæ‰€æœ‰é€‚ç”¨çš„åˆ†æ")
        print()
        print("ğŸ’¡ æˆ‘çš„å»ºè®®: " + " ".join(suggestions))
        print()
        
        while True:
            user_input = input("è¯·é€‰æ‹©åˆ†æç±»å‹ (ä¾‹å¦‚: 1 3 4 æˆ– all): ").strip()
            
            if not user_input:
                print("âŒ è¯·è¾“å…¥é€‰æ‹©")
                continue
            
            if user_input.lower() == 'all':
                # é€‰æ‹©æ‰€æœ‰æ¨èçš„åˆ†æ
                return suggestions + ['4', '5']  # æ·»åŠ ä¸€äº›é¢å¤–åˆ†æ
            
            # è§£æç”¨æˆ·è¾“å…¥
            choices = user_input.split()
            valid_choices = []
            
            for choice in choices:
                if choice in self.available_analyses and choice != 'all':
                    valid_choices.append(choice)
                else:
                    print(f"âš ï¸  æ— æ•ˆé€‰æ‹©: {choice}")
            
            if valid_choices:
                print(f"âœ… å°†æ‰§è¡Œä»¥ä¸‹åˆ†æ: {', '.join([self.available_analyses[c]['name'] for c in valid_choices])}")
                return valid_choices
            else:
                print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def _execute_analyses(self, selected_analyses: List[str]) -> None:
        """æ‰§è¡Œé€‰å®šçš„åˆ†æ"""
        print()
        print("ğŸ”¬ å¼€å§‹æ‰§è¡Œåˆ†æ...")
        print("=" * 50)
        
        for analysis_id in selected_analyses:
            analysis_name = self.available_analyses[analysis_id]['name']
            print(f"ğŸ“Š æ­£åœ¨æ‰§è¡Œ: {analysis_name}")
            
            if analysis_id == '1':
                self._basic_statistics()
            elif analysis_id == '2':
                self._missing_value_analysis()
            elif analysis_id == '3':
                self._distribution_analysis()
            elif analysis_id == '4':
                self._correlation_analysis()
            elif analysis_id == '5':
                self._outlier_detection()
            elif analysis_id == '6':
                self._trend_analysis()
            elif analysis_id == '7':
                self._categorical_analysis()
            
            print(f"âœ… å®Œæˆ: {analysis_name}")
            print()
    
    def _basic_statistics(self) -> None:
        """åŸºç¡€ç»Ÿè®¡åˆ†æ"""
        df = self.current_data
        
        basic_info = {
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'duplicated_rows': df.duplicated().sum(),
            'memory_usage': df.memory_usage(deep=True).sum()
        }
        
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            numeric_summary = df[numeric_cols].describe().to_dict()
        else:
            numeric_summary = {}
        
        self.analysis_results['basic_statistics'] = {
            'basic_info': basic_info,
            'numeric_summary': numeric_summary
        }
        
        # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
        print(f"   â€¢ æ•°æ®è¡Œæ•°: {basic_info['total_rows']}")
        print(f"   â€¢ é‡å¤è¡Œæ•°: {basic_info['duplicated_rows']}")
        if numeric_summary:
            print(f"   â€¢ æ•°å€¼å‹å˜é‡: {len(numeric_cols)}ä¸ª")
    
    def _missing_value_analysis(self) -> None:
        """ç¼ºå¤±å€¼åˆ†æ"""
        df = self.current_data
        missing_data = df.isnull().sum()
        
        missing_info = {
            'missing_counts': missing_data[missing_data > 0].to_dict(),
            'missing_percentage': (missing_data / len(df) * 100)[missing_data > 0].to_dict(),
            'complete_rows': len(df.dropna()),
            'rows_with_missing': len(df) - len(df.dropna())
        }
        
        self.analysis_results['missing_analysis'] = missing_info
        
        if missing_info['rows_with_missing'] > 0:
            print(f"   âš ï¸  å‘ç°ç¼ºå¤±å€¼: {missing_info['rows_with_missing']}è¡Œå—å½±å“")
            for col, count in list(missing_info['missing_counts'].items())[:3]:
                print(f"     â€¢ {col}: {count}ä¸ªç¼ºå¤±å€¼ ({missing_info['missing_percentage'][col]:.1f}%)")
        else:
            print("   âœ… æ— ç¼ºå¤±å€¼")
    
    def _distribution_analysis(self) -> None:
        """åˆ†å¸ƒåˆ†æå’Œå¯è§†åŒ–"""
        try:
            import plotly.express as px
            
            df = self.current_data
            numeric_cols = df.select_dtypes(include=['number']).columns
            charts = {}
            
            if len(numeric_cols) > 0:
                # ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—çš„åˆ†å¸ƒå›¾
                col = numeric_cols[0]
                fig = px.histogram(df, x=col, title=f'{col} åˆ†å¸ƒå›¾')
                charts['distribution'] = fig.to_html(include_plotlyjs='cdn')
                print(f"   ğŸ“ˆ å·²ç”Ÿæˆ {col} çš„åˆ†å¸ƒå›¾")
                
            self.analysis_results['visualizations'] = charts
            
        except ImportError:
            print("   âš ï¸  æœªå®‰è£…plotlyï¼Œè·³è¿‡å¯è§†åŒ–")
        except Exception as e:
            print(f"   âš ï¸  å¯è§†åŒ–å¤±è´¥: {str(e)}")
    
    def _correlation_analysis(self) -> None:
        """ç›¸å…³æ€§åˆ†æ"""
        try:
            import plotly.express as px
            
            df = self.current_data
            numeric_cols = df.select_dtypes(include=['number']).columns
            
            if len(numeric_cols) >= 2:
                corr_matrix = df[numeric_cols].corr()
                
                # æ‰¾å‡ºæœ€å¼ºç›¸å…³æ€§
                corr_pairs = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i+1, len(corr_matrix.columns)):
                        col1, col2 = corr_matrix.columns[i], corr_matrix.columns[j]
                        corr_val = corr_matrix.iloc[i, j]
                        corr_pairs.append((col1, col2, abs(corr_val), corr_val))
                
                # æŒ‰ç›¸å…³æ€§å¼ºåº¦æ’åº
                corr_pairs.sort(key=lambda x: x[2], reverse=True)
                
                self.analysis_results['correlation'] = {
                    'correlation_matrix': corr_matrix.to_dict(),
                    'top_correlations': corr_pairs[:5]
                }
                
                # ç”Ÿæˆçƒ­å›¾
                fig = px.imshow(corr_matrix, title='ç›¸å…³æ€§çƒ­å›¾', 
                               color_continuous_scale='RdBu_r', text_auto=True)
                
                if 'visualizations' not in self.analysis_results:
                    self.analysis_results['visualizations'] = {}
                self.analysis_results['visualizations']['correlation_heatmap'] = fig.to_html(include_plotlyjs='cdn')
                
                # æ˜¾ç¤ºæœ€å¼ºç›¸å…³æ€§
                if corr_pairs:
                    col1, col2, abs_corr, corr = corr_pairs[0]
                    print(f"   ğŸ”— æœ€å¼ºç›¸å…³æ€§: {col1} â†” {col2} (r={corr:.3f})")
                    
        except Exception as e:
            print(f"   âš ï¸  ç›¸å…³æ€§åˆ†æå¤±è´¥: {str(e)}")
    
    def _outlier_detection(self) -> None:
        """å¼‚å¸¸å€¼æ£€æµ‹"""
        df = self.current_data
        numeric_cols = df.select_dtypes(include=['number']).columns
        
        outlier_info = {}
        total_outliers = 0
        
        for col in numeric_cols[:3]:  # é™åˆ¶æ£€æµ‹çš„åˆ—æ•°
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
            outlier_count = len(outliers)
            total_outliers += outlier_count
            
            outlier_info[col] = {
                'count': outlier_count,
                'percentage': outlier_count / len(df) * 100,
                'bounds': [lower_bound, upper_bound]
            }
        
        self.analysis_results['outliers'] = outlier_info
        print(f"   ğŸ¯ æ£€æµ‹åˆ° {total_outliers} ä¸ªå¼‚å¸¸å€¼")
    
    def _trend_analysis(self) -> None:
        """ç®€å•è¶‹åŠ¿åˆ†æ"""
        print("   ğŸ“ˆ å°è¯•è¯†åˆ«æ—¶é—´ç›¸å…³åˆ—è¿›è¡Œè¶‹åŠ¿åˆ†æ")
        # ç®€åŒ–å®ç°ï¼Œå®é™…å¯ä»¥æ›´å¤æ‚
        self.analysis_results['trends'] = {'message': 'éœ€è¦æ˜ç¡®çš„æ—¶é—´åˆ—æ‰èƒ½è¿›è¡Œè¶‹åŠ¿åˆ†æ'}
    
    def _categorical_analysis(self) -> None:
        """åˆ†ç±»å˜é‡åˆ†æ"""
        try:
            import plotly.express as px
            
            df = self.current_data
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns
            
            if len(categorical_cols) > 0:
                col = categorical_cols[0]
                value_counts = df[col].value_counts().head(8)
                
                # ç”Ÿæˆé¥¼å›¾
                fig = px.pie(values=value_counts.values, names=value_counts.index,
                           title=f'{col} åˆ†å¸ƒé¥¼å›¾')
                
                if 'visualizations' not in self.analysis_results:
                    self.analysis_results['visualizations'] = {}
                self.analysis_results['visualizations']['category_pie'] = fig.to_html(include_plotlyjs='cdn')
                
                print(f"   ğŸ“Š å·²åˆ†æ {col}ï¼Œå‘ç° {df[col].nunique()} ä¸ªä¸åŒç±»åˆ«")
                
        except Exception as e:
            print(f"   âš ï¸  åˆ†ç±»åˆ†æå¤±è´¥: {str(e)}")
    
    def _generate_final_report(self) -> None:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        print("ğŸ“„ æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        # æ„é€ åˆ†æç»“æœ
        mock_result = {
            'query': 'äº¤äº’å¼æ•°æ®åˆ†æ',
            'insights': self._get_ai_insights(),
            'execution': self._format_results_for_report(),
            'execution_log': []
        }
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_content = self.report_generator.generate_report(
            mock_result,
            title=f"äº¤äº’å¼åˆ†ææŠ¥å‘Š - {self.current_file_info['file_name']}"
        )
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = f"interactive_report_{timestamp}.html"
        self.report_generator.save_report(html_content, report_path)
        
        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        
        # è¯¢é—®æ˜¯å¦æ‰“å¼€æŠ¥å‘Š
        open_report = input("æ˜¯å¦è¦åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹æŠ¥å‘Š? (y/n): ").strip().lower()
        if open_report in ['y', 'yes', 'æ˜¯']:
            import webbrowser
            webbrowser.open(f'file://{os.path.abspath(report_path)}')
    
    def _get_ai_insights(self) -> str:
        """è·å–AIç”Ÿæˆçš„æ´å¯Ÿ"""
        try:
            # å‡†å¤‡åˆ†æç»“æœæ‘˜è¦
            summary = f"æ•°æ®åŒ…å«{self.current_file_info['shape'][0]}è¡Œ{self.current_file_info['shape'][1]}åˆ—ã€‚"
            if 'basic_statistics' in self.analysis_results:
                basic = self.analysis_results['basic_statistics']['basic_info']
                if basic['duplicated_rows'] > 0:
                    summary += f"å‘ç°{basic['duplicated_rows']}è¡Œé‡å¤æ•°æ®ã€‚"
            
            insights = self.llm.analyze_data(summary, "ç»¼åˆåˆ†ææ•°æ®ç‰¹å¾å¹¶ç»™å‡ºä¸šåŠ¡å»ºè®®")
            return insights
        except:
            return "åŸºäºåˆ†æç»“æœï¼Œæ•°æ®è´¨é‡æ€»ä½“è‰¯å¥½ã€‚å»ºè®®æ ¹æ®å…·ä½“ä¸šåŠ¡éœ€æ±‚è¿›è¡Œæ·±å…¥åˆ†æã€‚"
    
    def _format_results_for_report(self) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ç»“æœç”¨äºæŠ¥å‘Š"""
        execution = {}
        
        if 'basic_statistics' in self.analysis_results:
            execution['step_stats'] = {
                'action': 'analyze_basic_stats',
                'success': True,
                'result': {'results': self.analysis_results['basic_statistics']}
            }
        
        if 'visualizations' in self.analysis_results:
            execution['step_viz'] = {
                'action': 'create_visualizations',
                'success': True,
                'result': {'results': self.analysis_results['visualizations']}
            }
        
        return execution
    
    def _continue_conversation(self) -> None:
        """ç»§ç»­å¯¹è¯"""
        print()
        print("ğŸ’¬ è¿˜æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿè¾“å…¥ 'quit' é€€å‡º")
        
        while True:
            user_input = input("\nä½ : ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            # ç®€å•å›å¤
            response = self.llm.chat([
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ï¼Œåˆšåˆšå®Œæˆäº†æ•°æ®åˆ†æã€‚è¯·ç®€æ´å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"},
                {"role": "user", "content": user_input}
            ])
            
            print(f"ğŸ¤–: {response}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python interactive_agent.py <æ–‡ä»¶è·¯å¾„>")
        print("ç¤ºä¾‹: python interactive_agent.py data.csv")
        sys.exit(1)
    
    file_path = sys.argv[1]
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        sys.exit(1)
    
    # å¯åŠ¨äº¤äº’å¼åˆ†æ
    agent = InteractiveDataAgent()
    agent.start_analysis(file_path)